{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Retrieve heating system info per building based on SiL data",
   "id": "f34ed54067e25173"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T09:08:02.925299Z",
     "start_time": "2025-04-19T09:08:02.535107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd"
   ],
   "id": "7ef743ded52c2036",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-17T16:53:13.810317Z",
     "start_time": "2025-04-17T16:53:13.808011Z"
    }
   },
   "source": [
    "shared_folder = '/Users/catarina/switchdrive/IPESE-DESL_data_exchange/SDEWES2025/data/'\n",
    "Qbuildings_file = shared_folder + 'buildings_SDEWES.gpkg'\n",
    "Qbuildings_exp_file = 'QBuildings_SDEWES_exp.csv'\n",
    "SiL_file = '/Users/catarina/switchdrive/SIL_UrbanTwin_data_exchange/Data/Gas and CAD network/Point_Energie.geojson'\n",
    "SiL_cleaned_file = 'SiL_cleaned.csv'\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T16:53:15.427772Z",
     "start_time": "2025-04-17T16:53:15.425219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_file(file):\n",
    "    \"\"\"\n",
    "    Function to read a file and return a dataframe\n",
    "    \n",
    "    Parameters:\n",
    "    - file: str ; Path to the file\n",
    "    \n",
    "    Returns:\n",
    "    - df: dataframe ; Dataframe with the file content\n",
    "    \"\"\"\n",
    "    # get extension of file\n",
    "    file_ext = file.split('.')[-1]\n",
    "    # check if the file is a .gpkg, .geojson or .csv. If none, raise an error\n",
    "    if file_ext in ['gpkg', 'geojson']:\n",
    "        df = gpd.read_file(file)\n",
    "    elif file_ext == 'csv':\n",
    "        df = pd.read_csv(file)\n",
    "    else:\n",
    "        raise ValueError('File must be a .gpkg, .geojson or .csv file')\n",
    "    return df"
   ],
   "id": "dc371efa811b8c6f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T16:53:18.369865Z",
     "start_time": "2025-04-17T16:53:17.758263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def explode_qbuildings(qbuildings):\n",
    "    # read the QBuildings file\n",
    "    qbuildings_df = read_file(qbuildings)\n",
    "\n",
    "    # Split the egid, ratio and in_class columns into separate columns based on /\n",
    "    for column in ['egid','ratio','id_class']:\n",
    "        qbuildings_df[column] = qbuildings_df[column].str.split('/')\n",
    "\n",
    "    # Create a copy of the egid column\n",
    "    qbuildings_df['egid_new'] = qbuildings_df['egid']\n",
    "\n",
    "    # Explode the columns\n",
    "    qbuildings_df = qbuildings_df.explode('egid')\n",
    "\n",
    "    # apply lambda function to extract the correct ratio and id_class values\n",
    "    for column in ['ratio','id_class']:\n",
    "        qbuildings_df[column] = qbuildings_df.apply(lambda row: row[column][row['egid_new'].index(str(row['egid']))], axis=1)\n",
    "\n",
    "    # drop the egid_new column\n",
    "    qbuildings_df.drop(columns='egid_new', inplace=True)\n",
    "    # Convert ration column to float\n",
    "    qbuildings_df['ratio'] = qbuildings_df['ratio'].astype(float)\n",
    "\n",
    "    # calculate new values of building parameters, based on the ratio TO DO: check if solar_gain_factor_signature_m2 should also be multiplied by the ratio\n",
    "    for column in ['area_era_m2','energy_heating_signature_kWh_y','energy_cooling_signature_kWh_y','power_heating_signature_kW','power_cooling_signature_kW','total_annual_irr_kWh_y','roof_annual_irr_kWh_y','facade_annual_irr_kWh_y','area_solar_m2','energy_hotwater_signature_kWh_y','power_hotwater_signature_W','waste_signature_kg_y','waste_signature_kW','area_net_floor_m2','area_footprint_m2','area_facade_m2','area_facade_solar_m2','area_roof_solar_m2','capita_cap','energy_el_kWh_y','solar_gain_factor_signature_m2','area_roof_m2','energy_heating_2024_kWh_y','energy_hotwater_2024_kWh_y']:\n",
    "        qbuildings_df[column] = qbuildings_df[column] * qbuildings_df['ratio']\n",
    "\n",
    "    # create a new column called id_building new, check if the id_building is a duplicate, and if so, add _1, _2, etc to the id_building\n",
    "    qbuildings_df['id_building_new'] = qbuildings_df['id_building']\n",
    "    qbuildings_df['id_building_new'] = qbuildings_df.groupby('id_building_new').cumcount()\n",
    "    qbuildings_df['id_building'] = qbuildings_df.apply(lambda row: row['id_building'] if row['id_building_new'] == 0 else f\"{row['id_building']}_{row['id_building_new']+1}\", axis=1)\n",
    "    # drop the id_building_new column\n",
    "    qbuildings_df.drop(columns='id_building_new', inplace=True)\n",
    "\n",
    "    # remove row with ratio = 0\n",
    "    qbuildings_df = qbuildings_df[qbuildings_df['ratio'] != 0]\n",
    "\n",
    "    qbuildings_df['ratio'] = 1.0 # ratio must be float\n",
    "\n",
    "    return qbuildings_df\n",
    "\n",
    "Qbuildings_exploded = explode_qbuildings(Qbuildings_file)\n",
    "Qbuildings_exploded.to_csv('QBuildings_SDEWES_exp.csv',index=False)\n"
   ],
   "id": "9f4d64c7590d98e1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T16:53:21.734045Z",
     "start_time": "2025-04-17T16:53:21.731625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_SiL(SiL_file):\n",
    "    \"\"\"\n",
    "    Function to remove qlEner_iEGID duplicates from the SiL dataframe keeping the row with the vaule with the highest qlEner_Densité\n",
    "\n",
    "    Parameters:\n",
    "    - SiL_file: str ; path to the SiL file. Can be a .gpkg, .geojson or .csv file\n",
    "\n",
    "    Returns\n",
    "    - updated SiL dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Read SiL file\n",
    "    SiL_df = read_file(SiL_file)\n",
    "\n",
    "    # Sort the dataframe by qlEner_Densité\n",
    "    SiL_df = SiL_df.sort_values('qlEner_Densité', ascending=False)\n",
    "\n",
    "    # Drop duplicates based on qlEner_iEGID\n",
    "    cleaned_SiL_df = SiL_df.drop_duplicates(subset='qlEner_iEGID', keep='first')\n",
    "\n",
    "\n",
    "    return cleaned_SiL_df\n",
    "\n",
    "#clean_SiL=clean_SiL(SiL_file)\n",
    "# clean_SiL.to_csv('SiL_cleaned.csv',index=False)"
   ],
   "id": "d40295ee42be636f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T16:53:25.126891Z",
     "start_time": "2025-04-17T16:53:25.122763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def update_QBuildings(qbuildings,update_data,QB_criteria,data_criteria,columns,data_new_name=None):\n",
    "    \"\"\"\n",
    "    Function to receive a path for a QBuildings file, a file path with data to be added to the QBuildings file, a list of columns with the data to be added and a list of criteria to match the data.\n",
    "    The function will update the QBuildings file with the data provided in the dataframe, based on the criteria.\n",
    "\n",
    "    Parameters:\n",
    "    - qbuildings: str ; Path to the QBuildings file. Can be a .gpkg, a .geojson or .csv file\n",
    "    - update_data: str ; Data to be added to the QBuildings file\n",
    "    - columns: list ; Columns with the data to be added\n",
    "    - QB_criteria: str ; Column in QBuildings to match the data\n",
    "    - data_criteria: str ; Column in data to update the QBuildings data\n",
    "    - data_new_name: list ; New name of the data to be added. Default is None\n",
    "\n",
    "    Returns:\n",
    "    - Updated QBuildings dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # read the QBuildings file\n",
    "    qbuildings_df = read_file(qbuildings)\n",
    "    # read the data to be added\n",
    "    update_data_df = read_file(update_data)\n",
    "\n",
    "    # Create columns with the data to be added and add the data to the QBuildings dataframe based on the criteria.\n",
    "    for column in columns:\n",
    "        qbuildings_df[column] = None\n",
    "        for index, row in update_data_df.iterrows():\n",
    "            qbuildings_df.loc[qbuildings_df[QB_criteria] == row[data_criteria], column] = row[column]\n",
    "\n",
    "    # Rename the columns with the new data\n",
    "    if data_new_name:\n",
    "        qbuildings_df.rename(columns=dict(zip(columns,data_new_name)), inplace=True)\n",
    "\n",
    "    return qbuildings_df"
   ],
   "id": "31237950351494",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Update QBuildings",
   "id": "f57369682d8979d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T16:53:31.410537Z",
     "start_time": "2025-04-17T16:53:29.934773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qbuildings = Qbuildings_exp_file\n",
    "update_data = SiL_cleaned_file\n",
    "QB_criteria = 'egid'\n",
    "data_criteria = 'qlEner_iEGID'\n",
    "columns = ['qlEner_sType','qlEner_sRecommendation']\n",
    "data_new_name = ['heating_system_2024','recommendation']\n",
    "\n",
    "Qbuildings_updated = update_QBuildings(qbuildings,update_data,QB_criteria,data_criteria,columns,data_new_name)\n",
    "\n",
    "heat_source_dic = {'Gaz': 'Gas', 'Mazout': 'Oil', 'CAD': 'DHN'}\n",
    "recommendation_dic = {'Sondes': 'HeatPump_Geothermal', 'CAD actuel': 'DHN', 'CAD futur': 'DHN_futur', 'CAD prévu': 'DHN_2050', 'Déjà raccordé': '2024', 'PAC Air Eau': 'HeatPump_Air', 'Sondes si rénovation': 'HeatPump_Geothermal', 'Gaz conservé': 'Gas', 'PAC si rénovation': 'HeatPump_Air', 'Gaz remplace mazout': 'Gas', 'Déjà raccordé remplaçable par sonde': '2024'}\n",
    "# Update QBuildings with heating system info and recommendation\n",
    "Qbuildings_updated['heating_system_2024']=Qbuildings_updated['heating_system_2024'].map(heat_source_dic)\n",
    "Qbuildings_updated['recommendation']=Qbuildings_updated['recommendation'].map(recommendation_dic)\n",
    "# fill none values in heating_system_2024 with the source_heating column\n",
    "Qbuildings_updated['heating_system_2024'] = Qbuildings_updated['heating_system_2024'].fillna(Qbuildings_updated['source_heating'])\n",
    "\n",
    "# In column id_class, replace XIII by V\n",
    "Qbuildings_updated['id_class'] = Qbuildings_updated['id_class'].replace('XIII','V')\n",
    "\n",
    "Qbuildings_updated.to_csv('../../QBuildings/QBuildings_SDEWES_updated.csv',index=False)"
   ],
   "id": "64933befcac6ca70",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:37:12.518790Z",
     "start_time": "2025-03-18T18:37:12.217382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# read the QBuildings file\n",
    "Qbuildings_file = '../../QBuildings/QBuildings_SDEWES_updated.csv'\n",
    "qbuildings_df = read_file(Qbuildings_file)\n",
    "\n",
    "# keep rows where in column 'heating_system_2024' is equal to Gas or Oil\n",
    "qbuildings_df = qbuildings_df[qbuildings_df['heating_system_2024'].isin(['Gas','Oil','DHN'])]\n",
    "qbuildings_df.to_csv('../../QBuildings/QBuildings_SDEWES_updated_2.csv',index=False)"
   ],
   "id": "6f19505e5126edf5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T18:15:09.048054Z",
     "start_time": "2025-03-16T18:15:08.727186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from reho.model.reho import *\n",
    "reader = QBuildingsReader()\n",
    "qbuildings_data = reader.read_csv(buildings_filename='/Users/catarina/Documents/REHO/scripts/Pathways/QBuildings/QBuildings_SDEWES_updated.csv',nb_buildings=2)"
   ],
   "id": "35e149f2e68f16fe",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T18:19:30.710157Z",
     "start_time": "2025-03-16T18:19:30.704410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for key in qbuildings_data['buildings_data'].keys():\n",
    "    print(qbuildings_data['buildings_data'][key].keys())"
   ],
   "id": "d2b5f9aaf5a7274e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['geometry', 'id_building', 'egid', 'id_class', 'class', 'ratio', 'status', 'period', 'n_p', 'ERA', 'SolarRoofArea', 'area_facade_m2', 'height_m', 'count_floor', 'source_heating', 'source_hotwater', 'U_h', 'HeatCapacity', 'T_comfort_min_0', 'Th_supply_0', 'Th_return_0', 'Tc_supply_0', 'Tc_return_0', 'x', 'y', 'z', 'transformer', 'energy_heating_signature_kWh_y', 'energy_cooling_signature_kWh_y', 'energy_hotwater_signature_kWh_y', 'energy_el_kWh_y', 'roof_annual_irr_kWh_y', 'facade_annual_irr_kWh_y'])\n",
      "dict_keys(['geometry', 'id_building', 'egid', 'id_class', 'class', 'ratio', 'status', 'period', 'n_p', 'ERA', 'SolarRoofArea', 'area_facade_m2', 'height_m', 'count_floor', 'source_heating', 'source_hotwater', 'U_h', 'HeatCapacity', 'T_comfort_min_0', 'Th_supply_0', 'Th_return_0', 'Tc_supply_0', 'Tc_return_0', 'x', 'y', 'z', 'transformer', 'energy_heating_signature_kWh_y', 'energy_cooling_signature_kWh_y', 'energy_hotwater_signature_kWh_y', 'energy_el_kWh_y', 'roof_annual_irr_kWh_y', 'facade_annual_irr_kWh_y'])\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pathway file",
   "id": "f5a0c2a2f86929f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:51:35.577855Z",
     "start_time": "2025-04-17T08:51:35.444336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file = ('/Users/catarina/Documents/REHO/scripts/Pathways/QBuildings/Pathway_SDEWES_updated.csv')\n",
    "\n",
    "pathways_df = pd.read_csv(file)\n",
    "\n",
    "# keep only egid and heating_system_2024 columns\n",
    "pathways_df = pathways_df[['egid','heating_system_2024','recommendation']]\n",
    "\n",
    "# substitute value 2024 in column recommendation by the value in heating_system_2024\n",
    "pathways_df['heating_system_2050'] = pathways_df.apply(lambda row: row['heating_system_2024'] if row['recommendation'] == '2024' else row['recommendation'], axis=1)\n",
    "\n",
    "pathways_df['heating_system_2050'] = pathways_df.apply(lambda row: 'DHN' if row['heating_system_2050'] in ['DHN_futur', 'DHN_2050'] else row['heating_system_2050'], axis=1)\n",
    "\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('DHN','DHN_hex')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('District heat','DHN_hex')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('District heat/Wood','DHN_hex')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Other/District heat','DHN_hex')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Other/District heat/Gas','DHN_hex')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('District heat/Other','DHN_hex')\n",
    "\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Gas','NG_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Other','NG_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Gas/Oil','NG_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Not determined','NG_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Gas/Other','NG_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Gas/Other/Oil','NG_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Gas/Other/Electricity/Oil/District heat','NG_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Other/Gas','NG_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('None/Gas','NG_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('None','NG_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Gas/Oil/Electricity/Other','NG_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Gas/Oil/Other/District heat','NG_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Gas/Wood/Oil','NG_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Gas/Oil/Other','NG_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Gas/Electricity','NG_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Gas/Other/Oil/District heat','NG_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Gas/Other/Oil/Electricity','NG_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Gas/District heat','NG_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Gas/Other/District heat','NG_Boiler')\n",
    "\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Oil','OIL_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Other/Oil/Gas','OIL_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Other/Oil','OIL_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Oil/Other','OIL_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Oil/Gas/Other','OIL_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Oil/Other/Gas','OIL_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('None/Oil/Other/Gas','OIL_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Oil/Not determined/Other/District heat','OIL_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Oil/Gas','OIL_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Oil/Gas/Wood','OIL_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Oil/Other/Not determined','OIL_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Oil/District heat','OIL_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Oil/Other/District heat','OIL_Boiler')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('None/Oil/Gas','OIL_Boiler')\n",
    "\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Air','HeatPump_Air')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Other/Air','HeatPump_Air')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Geothermal probe','HeatPump_Geothermal')\n",
    "\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Electricity','ElectricalHeater')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Wood','WOOD_Stove')\n",
    "pathways_df['heating_system_2024'] = pathways_df['heating_system_2024'].replace('Wood/Other','WOOD_Stove')\n",
    "\n",
    "pathways_df['heating_system_2050'] = pathways_df['heating_system_2050'].fillna('HeatPump_Air')\n",
    "pathways_df['heating_system_2050'] = pathways_df['heating_system_2050'].replace('DHN','DHN_hex')\n",
    "pathways_df['heating_system_2050'] = pathways_df['heating_system_2050'].replace('Gas','NG_Boiler')\n",
    "pathways_df['heating_system_2050'] = pathways_df['heating_system_2050'].replace('Oil','OIL_Boiler')\n",
    "\n",
    "pathways_df.drop(['recommendation'], axis=1, inplace=True)\n",
    "\n",
    "pathways_df['electric_system_2024'] = ''\n",
    "pathways_df['electric_system_2050'] = 'PV'\n",
    "\n",
    "# rename column heating_system_2024 by heating_system_2025\n",
    "pathways_df.rename(columns={'heating_system_2024': 'heating_system_2025'}, inplace=True)\n",
    "pathways_df.rename(columns={'electric_system_2024': 'electric_system_2025'}, inplace=True)\n",
    "\n",
    "# print unique values in column heating_system_2024\n",
    "unique_values = pathways_df['heating_system_2025'].unique()\n",
    "print(f\"Unique values in 'heating_system_2025' column:{unique_values}\")\n",
    "\n",
    "pathways_df.to_csv('../../QBuildings/Pathway_SDEWES_test.csv', index=False)\n",
    "\n",
    "#print(pathways_df)"
   ],
   "id": "d3dc781b69e14b42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'heating_system_2025' column:['NG_Boiler' 'OIL_Boiler' 'DHN_hex' 'ElectricalHeater' 'WOOD_Stove'\n",
      " 'HeatPump_Air' 'HeatPump_Geothermal']\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Divide Transformers with too many buildings in half",
   "id": "353eb13d419d8299"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T21:47:47.703823Z",
     "start_time": "2025-04-19T21:28:28.381760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "file = ('/Users/catarina/Documents/REHO/scripts/Pathways/QBuildings/QBuildings_SDEWES_updated_no_EH.csv')\n",
    "\n",
    "pathways_df = pd.read_csv(file)\n",
    "\n",
    "pathways_df['transformer_new'] = pathways_df['transformer']\n",
    "\n",
    "transf_list = pathways_df['transformer'].unique().tolist()\n",
    "\n",
    "for transform in transf_list:\n",
    "    # if number of rows > 100\n",
    "    group = pathways_df[pathways_df['transformer'] == transform]\n",
    "\n",
    "    # If group size > 200, split into 3 parts\n",
    "    if len(group) > 200:\n",
    "        n_rows = len(group)\n",
    "        span = np.linspace(0, n_rows, 4, endpoint=True, dtype=int)\n",
    "\n",
    "        # Assign new transformer values in three parts\n",
    "        indices = group.index\n",
    "        pathways_df.loc[indices[span[0]:span[1]], 'transformer_new'] = f'{transform}_2'\n",
    "        pathways_df.loc[indices[span[1]:span[2]], 'transformer_new'] = f'{transform}_3'\n",
    "        pathways_df.loc[indices[span[2]:span[3]], 'transformer_new'] = f'{transform}_4'\n",
    "\n",
    "    elif len(group) > 100:\n",
    "        n_rows = len(group)\n",
    "        span = np.linspace(0, n_rows, 3, endpoint=True, dtype=int)\n",
    "\n",
    "        # Assign new transformer values in three parts\n",
    "        indices = group.index\n",
    "        pathways_df.loc[indices[span[0]:span[1]], 'transformer_new'] = f'{transform}_2'\n",
    "        pathways_df.loc[indices[span[1]:span[2]], 'transformer_new'] = f'{transform}_3'\n",
    "\n",
    "pathways_df.to_csv('../../QBuildings/QBuildings_SDEWES_updated_no_EH_transf.csv', index=False)\n"
   ],
   "id": "cd0d67e560340b5f",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[36]\u001B[39m\u001B[32m, line 36\u001B[39m\n\u001B[32m     33\u001B[39m         pathways_df.loc[indices[span[\u001B[32m0\u001B[39m]:span[\u001B[32m1\u001B[39m]], \u001B[33m'\u001B[39m\u001B[33mtransformer_new\u001B[39m\u001B[33m'\u001B[39m] = \u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtransform\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m_2\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m     34\u001B[39m         pathways_df.loc[indices[span[\u001B[32m1\u001B[39m]:span[\u001B[32m2\u001B[39m]], \u001B[33m'\u001B[39m\u001B[33mtransformer_new\u001B[39m\u001B[33m'\u001B[39m] = \u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtransform\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m_3\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m36\u001B[39m \u001B[43mpathways_df\u001B[49m.to_csv(\u001B[33m'\u001B[39m\u001B[33m../../QBuildings/QBuildings_SDEWES_updated_no_EH_transf.csv\u001B[39m\u001B[33m'\u001B[39m, index=\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m_pydevd_bundle/pydevd_cython_darwin_312_64.pyx:1187\u001B[39m, in \u001B[36m_pydevd_bundle.pydevd_cython_darwin_312_64.SafeCallWrapper.__call__\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m_pydevd_bundle/pydevd_cython_darwin_312_64.pyx:627\u001B[39m, in \u001B[36m_pydevd_bundle.pydevd_cython_darwin_312_64.PyDBFrame.trace_dispatch\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m_pydevd_bundle/pydevd_cython_darwin_312_64.pyx:937\u001B[39m, in \u001B[36m_pydevd_bundle.pydevd_cython_darwin_312_64.PyDBFrame.trace_dispatch\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m_pydevd_bundle/pydevd_cython_darwin_312_64.pyx:928\u001B[39m, in \u001B[36m_pydevd_bundle.pydevd_cython_darwin_312_64.PyDBFrame.trace_dispatch\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m_pydevd_bundle/pydevd_cython_darwin_312_64.pyx:585\u001B[39m, in \u001B[36m_pydevd_bundle.pydevd_cython_darwin_312_64.PyDBFrame.do_wait_suspend\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Applications/PyCharm.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1220\u001B[39m, in \u001B[36mPyDB.do_wait_suspend\u001B[39m\u001B[34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[39m\n\u001B[32m   1217\u001B[39m         from_this_thread.append(frame_id)\n\u001B[32m   1219\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._threads_suspended_single_notification.notify_thread_suspended(thread_id, stop_reason):\n\u001B[32m-> \u001B[39m\u001B[32m1220\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Applications/PyCharm.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1235\u001B[39m, in \u001B[36mPyDB._do_wait_suspend\u001B[39m\u001B[34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[39m\n\u001B[32m   1232\u001B[39m             \u001B[38;5;28mself\u001B[39m._call_mpl_hook()\n\u001B[32m   1234\u001B[39m         \u001B[38;5;28mself\u001B[39m.process_internal_commands()\n\u001B[32m-> \u001B[39m\u001B[32m1235\u001B[39m         \u001B[43mtime\u001B[49m\u001B[43m.\u001B[49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1237\u001B[39m \u001B[38;5;28mself\u001B[39m.cancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[32m   1239\u001B[39m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T23:33:53.683487Z",
     "start_time": "2025-04-20T23:33:53.327140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "file = ('/Users/catarina/Documents/REHO/scripts/Pathways/QBuildings/QBuildings_SDEWES_updated_no_EH.csv')\n",
    "\n",
    "pathways_df = pd.read_csv(file)\n",
    "\n",
    "n_rows = len(pathways_df)\n",
    "\n",
    "n_groups = n_rows // 70\n",
    "\n",
    "span = np.linspace(0, n_rows, n_groups, endpoint=True, dtype=int)\n",
    "indices = pathways_df.index\n",
    "for i in range(1, n_groups):\n",
    "    pathways_df.loc[indices[span[i-1]:span[i]], 'transformer_new'] = f'group_{i}'\n",
    "pathways_df.to_csv('../../QBuildings/QBuildings_SDEWES_updated_no_EH_2.csv', index=False)"
   ],
   "id": "e103e8b616398851",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T10:04:54.413990Z",
     "start_time": "2025-04-21T10:04:53.320123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "transf = pd.read_csv('../../QBuildings/QBuildings_SDEWES_updated_no_EH_2.csv', usecols=['transformer_new'])\n",
    "transf_list = transf['transformer_new'].unique().tolist()\n",
    "\n",
    "\n",
    "results_folder = ('/Users/catarina/switchdrive/IPESE-DESL_data_exchange/SDEWES2025/1st Results')\n",
    "\n",
    "for transform in transf_list:\n",
    "    results = pd.read_pickle(f'{results_folder}/pathway_{transform}.pickle')\n",
    "    results = results['pathway']\n",
    "\n",
    "    results_max_PV = results['PV_max']['df_Unit']\n",
    "    PV_max = results_max_PV.loc[(results_max_PV.index.str.contains('PV')) & ~(results_max_PV.index.str.contains('district'))]\n",
    "    PV_max = PV_max['Units_Mult'].sum()\n",
    "\n",
    "    results_2050_PV = results[5]['df_Unit']\n",
    "    PV_2050 = results_2050_PV.loc[(results_2050_PV.index.str.contains('PV')) & ~(results_2050_PV.index.str.contains('district'))]\n",
    "    PV_2050 = PV_2050['Units_Mult'].sum()\n",
    "\n",
    "    test = PV_max - PV_2050\n",
    "    print(f'Transformer: {transform}, PV_max: {PV_max}, PV_2050: {PV_2050}, Difference: {test}')\n"
   ],
   "id": "ac21e8d33dc6e6e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer: group_1, PV_max: 4464.639999999999, PV_2050: 4476.58503095255, Difference: -11.945030952550951\n",
      "Transformer: group_2, PV_max: 3750.0800000000004, PV_2050: 3762.49499335108, Difference: -12.41499335107983\n",
      "Transformer: group_3, PV_max: 4843.2, PV_2050: 4854.317919043891, Difference: -11.117919043891561\n",
      "Transformer: group_4, PV_max: 4405.76, PV_2050: 4417.18357178876, Difference: -11.423571788759546\n",
      "Transformer: group_5, PV_max: 6132.16, PV_2050: 6144.2241001169195, Difference: -12.06410011691969\n",
      "Transformer: group_6, PV_max: 6673.919999999999, PV_2050: 6684.47401264571, Difference: -10.554012645710827\n",
      "Transformer: group_7, PV_max: 4486.400000000001, PV_2050: 4499.00194858386, Difference: -12.601948583859667\n",
      "Transformer: group_8, PV_max: 4130.5599999999995, PV_2050: 4142.10426967232, Difference: -11.544269672320297\n",
      "Transformer: group_9, PV_max: 3758.72, PV_2050: 3770.81207582478, Difference: -12.092075824780295\n",
      "Transformer: group_10, PV_max: 3369.9200000000005, PV_2050: 3381.4892925054796, Difference: -11.569292505479098\n",
      "Transformer: group_11, PV_max: 3319.68, PV_2050: 3332.27062242953, Difference: -12.590622429529958\n",
      "Transformer: group_12, PV_max: 2961.9200000000005, PV_2050: 2974.4283292288405, Difference: -12.508329228840012\n",
      "Transformer: group_13, PV_max: 7021.439999999999, PV_2050: 7034.521313394041, Difference: -13.0813133940419\n",
      "Transformer: group_14, PV_max: 6824.640000000002, PV_2050: 6835.84396658581, Difference: -11.203966585808303\n",
      "Transformer: group_15, PV_max: 4817.6, PV_2050: 4829.72890508754, Difference: -12.128905087539351\n",
      "Transformer: group_16, PV_max: 5747.840000000001, PV_2050: 5760.7067406497, Difference: -12.86674064969884\n",
      "Transformer: group_17, PV_max: 4882.880000000001, PV_2050: 4894.35205978806, Difference: -11.472059788058687\n",
      "Transformer: group_18, PV_max: 9157.760000000002, PV_2050: 9170.249155064841, Difference: -12.489155064838997\n",
      "Transformer: group_19, PV_max: 5909.4400000000005, PV_2050: 5922.26496174958, Difference: -12.824961749579415\n",
      "Transformer: group_20, PV_max: 7372.4800000000005, PV_2050: 7384.446892809431, Difference: -11.966892809430647\n",
      "Transformer: group_21, PV_max: 7837.760000000001, PV_2050: 7849.8444298902, Difference: -12.084429890199317\n",
      "Transformer: group_22, PV_max: 6352.96, PV_2050: 6364.959701581649, Difference: -11.999701581648878\n",
      "Transformer: group_23, PV_max: 4797.4400000000005, PV_2050: 4809.2425551298, Difference: -11.802555129799657\n",
      "Transformer: group_24, PV_max: 5542.719999999999, PV_2050: 5554.8333630117, Difference: -12.11336301170104\n",
      "Transformer: group_25, PV_max: 11786.560000000001, PV_2050: 11799.050140420542, Difference: -12.490140420541138\n",
      "Transformer: group_26, PV_max: 5631.360000000001, PV_2050: 5643.57189481489, Difference: -12.211894814889092\n",
      "Transformer: group_27, PV_max: 6087.360000000001, PV_2050: 6098.3685370883895, Difference: -11.008537088388948\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6d68d97947dbb588"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
